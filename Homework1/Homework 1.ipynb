{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 documents the execution times are:\n",
      "Shingling\n",
      "Jaccard similarity between document 13 and 33 is 0.808\n",
      "Jaccard similarity between document 31 and 34 is 1.0\n",
      "Jaccard similarity between document 46 and 59 is 0.979\n",
      "Jaccard similarity between document 57 and 62 is 1.0\n",
      "Execution time for Shingling is 0.45 seconds\n",
      "MinHashing\n",
      "Jaccard similarity between document 13 and 33 is 0.8666666666666667\n",
      "Jaccard similarity between document 31 and 34 is 1.0\n",
      "Jaccard similarity between document 46 and 59 is 1.0\n",
      "Jaccard similarity between document 57 and 62 is 1.0\n",
      "Execution time for MinHashing is 0.581 seconds\n",
      "LSH\n",
      "Execution time for LSH: 0.147 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import collections\n",
    "from itertools import combinations\n",
    "\n",
    "class Shingling():\n",
    "    \n",
    "    shingles = []\n",
    "\n",
    "    def k_shingle(self, text, shingle_size_k: int):\n",
    "        shingles = []\n",
    "        #go through text and add hashed text snippets of shingle size to array\n",
    "        for index in range(len(text)-shingle_size_k+1):\n",
    "            shingle=[text[index+i] for i in range(shingle_size_k)]\n",
    "            shingle = ' '.join(shingle)\n",
    "            shingles.append(hash(shingle))\n",
    "        return list(dict.fromkeys(shingles))\n",
    "    \n",
    "\n",
    "    def __init__(self, text: str, shingle_size_k: int):\n",
    "        self.shingles = self.k_shingle(text, shingle_size_k)\n",
    "\n",
    "\n",
    "class CompareSets():\n",
    "\n",
    "    jaccard_similarity = -1\n",
    "\n",
    "    def compare(self, set1: list, set2: list):\n",
    "        x = set(set1)\n",
    "        y = set(set2)\n",
    "        union = x.union(y)\n",
    "        intersection = x.intersection(y)\n",
    "        return round(len(intersection)/(len(union)), 3)\n",
    "     \n",
    "    def __init__(self, set1: list, set2: list):\n",
    "        self.jaccard_similarity = self.compare(set1, set2)\n",
    "\n",
    "\n",
    "\n",
    "class MinHashing():\n",
    "    \n",
    "    signature = None\n",
    "\n",
    "    \n",
    "    def get_signature(self, a: list, b: list, numHashes, shingleSet):\n",
    "        signature = []\n",
    "        Nextprime = 4294967311\n",
    "        for i in range(0, numHashes):\n",
    "            minHashCode = Nextprime + 1\n",
    "            for shingle in shingleSet:\n",
    "                hash_code = (a[i] * shingle + b[i]) % Nextprime\n",
    "                if hash_code < minHashCode:\n",
    "                    minHashCode = hash_code\n",
    "            signature.append(minHashCode)\n",
    "        return signature\n",
    "\n",
    "\n",
    "    def __init__(self, a: list, b: list, numHashes: int, shingleSet):\n",
    "        self.signature = self.get_signature(a, b,numHashes, shingleSet)\n",
    "\n",
    "\n",
    "class CompareSignatures():\n",
    "    \n",
    "    estimated_similarity = -1\n",
    "\n",
    "    def compare(self, n, set1: list, set2: list):\n",
    "        c = 0\n",
    "        for k in range(0, n):\n",
    "            if set1[k] == set2[k]:\n",
    "                c = c + 1\n",
    "\n",
    "        return c/n\n",
    "\n",
    "    def __init__(self, n: int, set1: list, set2: list):\n",
    "        self.estimated_similarity = self.compare(n,set1, set2)\n",
    "\n",
    "\n",
    "class LSH():\n",
    "\n",
    "    candidate_pairs = []\n",
    "\n",
    "    def lsh(self, signatures: list, sim_threshold: float):\n",
    "\n",
    "        n_bands = 4\n",
    "        n_rows = 10\n",
    "\n",
    "        # make an empty bucket for every band\n",
    "        n_buckets = 10000\n",
    "        buckets = [[[] for _ in range(n_buckets)] for _ in range(n_bands)]\n",
    "\n",
    "        for i, signature in enumerate(signatures):\n",
    "            for k in range(0, n_bands):\n",
    "                # concatenate and hash into a bucket\n",
    "                snippet = ''.join([\n",
    "                    str(x) for x in signature[k * n_rows:k * n_rows + n_rows]\n",
    "                ])\n",
    "                bucket = hash(snippet) % n_buckets\n",
    "                buckets[k][bucket].append(i + 1)\n",
    "\n",
    "        # clear buckets of duplicates\n",
    "        for i, bucket in enumerate(buckets):\n",
    "            for k, element in enumerate(bucket):\n",
    "                element = list(dict.fromkeys(element))\n",
    "\n",
    "        # make sure that buckets have more than 1 signature\n",
    "        for i, bucket in enumerate(buckets):\n",
    "            if len(bucket) < 2:\n",
    "                buckets.pop(i)\n",
    "\n",
    "        possible_pairs = []\n",
    "        # make all possible pairs\n",
    "        for bucket_band in buckets:\n",
    "            for bucket in bucket_band:\n",
    "                pairs = [i for i in combinations(bucket, 2)]\n",
    "                possible_pairs += pairs\n",
    "\n",
    "        c = collections.Counter(possible_pairs)\n",
    "        hits = []\n",
    "        for i, value in enumerate(c.values()):\n",
    "            if (value / n_bands) >= sim_threshold**n_rows:\n",
    "                hits.append(i)\n",
    "        candidate_pairs = []\n",
    "        for i, pair in enumerate(c.keys()):\n",
    "            if i in hits:\n",
    "                candidate_pairs.append(pair)\n",
    "\n",
    "        return candidate_pairs\n",
    "\n",
    "    def __init__(self, signatures: list, sim_threshold: float):\n",
    "        self.candidate_pairs = self.lsh(signatures, sim_threshold)\n",
    "\n",
    "def get_random_coeff(shingle_size_k):\n",
    "    maxShingleId = 2**32 - 1\n",
    "    randomList = []\n",
    "    while shingle_size_k > 0:\n",
    "        randomIndex = random.randint(0, maxShingleId)\n",
    "        while randomIndex in randomList:\n",
    "            randomIndex = random.randint(0, maxShingleId)\n",
    "        randomList.append(randomIndex)\n",
    "        shingle_size_k = shingle_size_k - 1\n",
    "    return randomList\n",
    "\n",
    "def main():   \n",
    "    \n",
    "    # config\n",
    "    \n",
    "    threshold = 0.8\n",
    "    shingle_size_k = 5\n",
    "    num_docs = 100\n",
    "    print('For {} documents the execution times are:'.format(num_docs))\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    #  Prepare Data  #  \n",
    "    ##################\n",
    "    \n",
    "    data = []\n",
    "  \n",
    "    #extract text from dataset\n",
    "    for file in os.listdir(\"data/\"):\n",
    "        if file.endswith(\".sgm\"):\n",
    "            filename = os.path.join(\"data\", file)\n",
    "            f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "            dataFile = f.read()\n",
    "            soup = BeautifulSoup(dataFile, 'html.parser')\n",
    "            contents = soup.findAll('body')\n",
    "            for content in contents:\n",
    "                data.append(content.text)\n",
    "\n",
    "    #make text lowercase and remove punctuation\n",
    "    for i in data:\n",
    "        i = i.lower()\n",
    "        i = i.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "\n",
    "    \n",
    "    data= list(map(lambda text: re.sub(r'http\\S+', '', text, flags=re.MULTILINE), data))\n",
    "    \n",
    "    def removeHTMLTags(text):\n",
    "        text = re.sub(r'<.*?>', '', text, flags=re.MULTILINE)\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    for i in range(100):\n",
    "        data[i]=data[i].lower()\n",
    "        data[i] = data[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    data= list(map(removeHTMLTags, data))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######################\n",
    "    #  Shingle Documents  #  \n",
    "    #######################\n",
    "\n",
    "    \n",
    "    print('Shingling')\n",
    "    shingled_documents = []\n",
    "    begin = time.time()\n",
    "    for i in range(num_docs):\n",
    "        shingled_documents.append(Shingling(data[i], shingle_size_k))\n",
    "        \n",
    "    for i in range(len(shingled_documents)-1):\n",
    "        for j in range(i+1, len(shingled_documents)):\n",
    "            similarity = CompareSets(shingled_documents[i].shingles, shingled_documents[j].shingles).jaccard_similarity\n",
    "            if similarity > threshold:\n",
    "                print('Jaccard similarity between document {} and {} is {}'.format(i, j, similarity))\n",
    "    end = time.time()\n",
    "    print('Execution time for Shingling is {} seconds'.format(round(end-begin , 2)))\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    #  MinHash Shingles and calculate Jaccard Similarity #  \n",
    "    ######################################################\n",
    "    \n",
    "    print('MinHashing')\n",
    "    begin = time.time()\n",
    "    NumHash = 30\n",
    "    a = get_random_coeff(NumHash)           \n",
    "    b = get_random_coeff(NumHash)\n",
    "    \n",
    "    minhash_documents = []\n",
    "    for i in range(num_docs):\n",
    "        minhash_documents.append(MinHashing(a, b,NumHash, shingled_documents[i].shingles))\n",
    "    for i in range(len(minhash_documents)-1):\n",
    "        for j in range(i+1, len(minhash_documents)):\n",
    "            similarity = CompareSignatures(NumHash,minhash_documents[i].signature, minhash_documents[j].signature).estimated_similarity\n",
    "            if similarity > threshold:\n",
    "                print('Jaccard similarity between document {} and {} is {}'.format(i, j, similarity))\n",
    "    end = time.time()\n",
    "    print('Execution time for MinHashing is {} seconds'.format(round(end-begin, 3)))\n",
    "    \n",
    "    print('LSH')\n",
    "    begin = time.time()\n",
    "    k=[i.signature for i in minhash_documents]\n",
    "    lsh = LSH(k, 0.8)\n",
    "    end = time.time()\n",
    "    print('Execution time for LSH: {} seconds'.format(round(end-begin, 3)))\n",
    "\n",
    "main()\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
